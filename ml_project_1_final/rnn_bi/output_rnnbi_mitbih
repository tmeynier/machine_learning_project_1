Sender: LSF System <lsfadmin@lo-s4-003>
Subject: Job 5169306: <python RNNbi_mitbih.py> in cluster <leonhard> Done

Job <python RNNbi_mitbih.py> was submitted from host <lo-login-01> by user <mchevalley> in cluster <leonhard> at Mon Mar  9 21:06:30 2020
Job was executed on host(s) <lo-s4-003>, in queue <gpu.24h>, as user <mchevalley> in cluster <leonhard> at Mon Mar  9 21:07:00 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1> was used as the working directory.
Started at Mon Mar  9 21:07:00 2020
Terminated at Mon Mar  9 22:18:45 2020
Results reported at Mon Mar  9 22:18:45 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python RNNbi_mitbih.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6131.01 sec.
    Max Memory :                                 3129 MB
    Average Memory :                             3097.65 MB
    Total Requested Memory :                     8192.00 MB
    Delta Memory :                               5063.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                21
    Run time :                                   4309 sec.
    Turnaround time :                            4335 sec.

The output (if any) follows:

2020-03-09 21:07:06.544776: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-09 21:07:06.547548: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-09 21:07:06.547588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-09 21:07:16.457503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-09 21:07:16.538928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-09 21:07:16.545451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-09 21:07:16.579919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-09 21:07:16.602915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-09 21:07:16.614660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-09 21:07:16.650909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-09 21:07:16.664188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-09 21:07:16.734588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-09 21:07:16.743887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-09 21:07:16.745085: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-09 21:07:16.758327: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199985000 Hz
2020-03-09 21:07:16.758590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5462dd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-09 21:07:16.758622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-09 21:07:16.976470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54d13e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-09 21:07:16.976525: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-09 21:07:16.979665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-09 21:07:16.979737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-09 21:07:16.979759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-09 21:07:16.979777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-09 21:07:16.979795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-09 21:07:16.979813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-09 21:07:16.979831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-09 21:07:16.979850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-09 21:07:16.986953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-09 21:07:16.988799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-09 21:07:16.992953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-09 21:07:16.992992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-09 21:07:16.993004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-09 21:07:16.999882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)
2020-03-09 21:07:25.704328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
bidirectional_1 (Bidirection (None, 187, 60)           7680      
_________________________________________________________________
bidirectional_2 (Bidirection (None, 60)                21840     
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 305       
=================================================================
Total params: 29,825
Trainable params: 29,825
Non-trainable params: 0
_________________________________________________________________
Train on 78798 samples, validate on 8756 samples
Epoch 1/1000
 - 111s - loss: 0.5491 - acc: 0.8496 - val_loss: 0.3317 - val_acc: 0.9079

Epoch 00001: val_acc improved from -inf to 0.90795, saving model to rnn_bi_mitbih.h5
Epoch 2/1000
 - 109s - loss: 0.2797 - acc: 0.9294 - val_loss: 0.2446 - val_acc: 0.9336

Epoch 00002: val_acc improved from 0.90795 to 0.93365, saving model to rnn_bi_mitbih.h5
Epoch 3/1000
 - 107s - loss: 0.2080 - acc: 0.9446 - val_loss: 0.1789 - val_acc: 0.9492

Epoch 00003: val_acc improved from 0.93365 to 0.94918, saving model to rnn_bi_mitbih.h5
Epoch 4/1000
 - 108s - loss: 0.1687 - acc: 0.9540 - val_loss: 0.1513 - val_acc: 0.9571

Epoch 00004: val_acc improved from 0.94918 to 0.95706, saving model to rnn_bi_mitbih.h5
Epoch 5/1000
 - 108s - loss: 0.1436 - acc: 0.9599 - val_loss: 0.1264 - val_acc: 0.9649

Epoch 00005: val_acc improved from 0.95706 to 0.96494, saving model to rnn_bi_mitbih.h5
Epoch 6/1000
 - 108s - loss: 0.1243 - acc: 0.9650 - val_loss: 0.1236 - val_acc: 0.9656

Epoch 00006: val_acc improved from 0.96494 to 0.96562, saving model to rnn_bi_mitbih.h5
Epoch 7/1000
 - 108s - loss: 0.1125 - acc: 0.9679 - val_loss: 0.1107 - val_acc: 0.9688

Epoch 00007: val_acc improved from 0.96562 to 0.96882, saving model to rnn_bi_mitbih.h5
Epoch 8/1000
 - 108s - loss: 0.1024 - acc: 0.9703 - val_loss: 0.1031 - val_acc: 0.9709

Epoch 00008: val_acc improved from 0.96882 to 0.97088, saving model to rnn_bi_mitbih.h5
Epoch 9/1000
 - 108s - loss: 0.0938 - acc: 0.9731 - val_loss: 0.1068 - val_acc: 0.9703

Epoch 00009: val_acc did not improve from 0.97088
Epoch 10/1000
 - 106s - loss: 0.0930 - acc: 0.9729 - val_loss: 0.0898 - val_acc: 0.9754

Epoch 00010: val_acc improved from 0.97088 to 0.97545, saving model to rnn_bi_mitbih.h5
Epoch 11/1000
 - 107s - loss: 0.0873 - acc: 0.9754 - val_loss: 0.0877 - val_acc: 0.9751

Epoch 00011: val_acc did not improve from 0.97545
Epoch 12/1000
 - 108s - loss: 0.0771 - acc: 0.9777 - val_loss: 0.0776 - val_acc: 0.9783

Epoch 00012: val_acc improved from 0.97545 to 0.97830, saving model to rnn_bi_mitbih.h5
Epoch 13/1000
 - 107s - loss: 0.0797 - acc: 0.9773 - val_loss: 0.0836 - val_acc: 0.9773

Epoch 00013: val_acc did not improve from 0.97830
Epoch 14/1000
 - 107s - loss: 0.0722 - acc: 0.9789 - val_loss: 0.0786 - val_acc: 0.9778

Epoch 00014: val_acc did not improve from 0.97830
Epoch 15/1000
 - 108s - loss: 0.0685 - acc: 0.9802 - val_loss: 0.0726 - val_acc: 0.9797

Epoch 00015: val_acc improved from 0.97830 to 0.97967, saving model to rnn_bi_mitbih.h5
Epoch 16/1000
 - 108s - loss: 0.0630 - acc: 0.9818 - val_loss: 0.0706 - val_acc: 0.9812

Epoch 00016: val_acc improved from 0.97967 to 0.98116, saving model to rnn_bi_mitbih.h5
Epoch 17/1000
 - 107s - loss: 0.0633 - acc: 0.9813 - val_loss: 0.0713 - val_acc: 0.9796

Epoch 00017: val_acc did not improve from 0.98116
Epoch 18/1000
 - 108s - loss: 0.0625 - acc: 0.9820 - val_loss: 0.0632 - val_acc: 0.9806

Epoch 00018: val_acc did not improve from 0.98116
Epoch 19/1000
 - 110s - loss: 0.0607 - acc: 0.9822 - val_loss: 0.0627 - val_acc: 0.9818

Epoch 00019: val_acc improved from 0.98116 to 0.98184, saving model to rnn_bi_mitbih.h5
Epoch 20/1000
 - 108s - loss: 0.0608 - acc: 0.9822 - val_loss: 0.0678 - val_acc: 0.9805

Epoch 00020: val_acc did not improve from 0.98184
Epoch 21/1000
 - 107s - loss: 0.0546 - acc: 0.9843 - val_loss: 0.0622 - val_acc: 0.9818

Epoch 00021: val_acc did not improve from 0.98184
Epoch 22/1000
 - 108s - loss: 0.0534 - acc: 0.9844 - val_loss: 0.0598 - val_acc: 0.9831

Epoch 00022: val_acc improved from 0.98184 to 0.98310, saving model to rnn_bi_mitbih.h5
Epoch 23/1000
 - 108s - loss: 0.0514 - acc: 0.9851 - val_loss: 0.0604 - val_acc: 0.9828

Epoch 00023: val_acc did not improve from 0.98310
Epoch 24/1000
 - 108s - loss: 0.0517 - acc: 0.9848 - val_loss: 0.0597 - val_acc: 0.9837

Epoch 00024: val_acc improved from 0.98310 to 0.98367, saving model to rnn_bi_mitbih.h5
Epoch 25/1000
 - 108s - loss: 0.0481 - acc: 0.9860 - val_loss: 0.0634 - val_acc: 0.9831

Epoch 00025: val_acc did not improve from 0.98367
Epoch 26/1000
 - 107s - loss: 0.0486 - acc: 0.9855 - val_loss: 0.0571 - val_acc: 0.9846

Epoch 00026: val_acc improved from 0.98367 to 0.98458, saving model to rnn_bi_mitbih.h5
Epoch 27/1000
 - 108s - loss: 0.0434 - acc: 0.9877 - val_loss: 0.0563 - val_acc: 0.9858

Epoch 00027: val_acc improved from 0.98458 to 0.98584, saving model to rnn_bi_mitbih.h5
Epoch 28/1000
 - 107s - loss: 0.0469 - acc: 0.9859 - val_loss: 0.0652 - val_acc: 0.9830

Epoch 00028: val_acc did not improve from 0.98584
Epoch 29/1000
 - 107s - loss: 0.0445 - acc: 0.9865 - val_loss: 0.0619 - val_acc: 0.9831

Epoch 00029: val_acc did not improve from 0.98584
Epoch 30/1000
 - 107s - loss: 0.0482 - acc: 0.9853 - val_loss: 0.0566 - val_acc: 0.9841

Epoch 00030: val_acc did not improve from 0.98584

Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
Epoch 31/1000
 - 107s - loss: 0.0349 - acc: 0.9901 - val_loss: 0.0481 - val_acc: 0.9878

Epoch 00031: val_acc improved from 0.98584 to 0.98778, saving model to rnn_bi_mitbih.h5
Epoch 32/1000
 - 107s - loss: 0.0304 - acc: 0.9911 - val_loss: 0.0470 - val_acc: 0.9882

Epoch 00032: val_acc improved from 0.98778 to 0.98824, saving model to rnn_bi_mitbih.h5
Epoch 33/1000
 - 107s - loss: 0.0289 - acc: 0.9915 - val_loss: 0.0471 - val_acc: 0.9879

Epoch 00033: val_acc did not improve from 0.98824
Epoch 34/1000
 - 107s - loss: 0.0276 - acc: 0.9918 - val_loss: 0.0472 - val_acc: 0.9879

Epoch 00034: val_acc did not improve from 0.98824
Epoch 35/1000
 - 107s - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0470 - val_acc: 0.9880

Epoch 00035: val_acc did not improve from 0.98824

Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
Epoch 36/1000
 - 106s - loss: 0.0250 - acc: 0.9925 - val_loss: 0.0468 - val_acc: 0.9879

Epoch 00036: val_acc did not improve from 0.98824
Epoch 37/1000
 - 108s - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0469 - val_acc: 0.9877

Epoch 00037: val_acc did not improve from 0.98824
Epoch 38/1000
 - 107s - loss: 0.0245 - acc: 0.9927 - val_loss: 0.0469 - val_acc: 0.9878

Epoch 00038: val_acc did not improve from 0.98824

Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
Epoch 39/1000
 - 107s - loss: 0.0243 - acc: 0.9927 - val_loss: 0.0469 - val_acc: 0.9878
Using TensorFlow backend.

Epoch 00039: val_acc did not improve from 0.98824
Epoch 00039: early stopping
Test f1 score : 0.915409794008698 
Test accuracy score : 0.9850630367257446 
