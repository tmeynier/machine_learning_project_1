Sender: LSF System <lsfadmin@lo-s4-034>
Subject: Job 5092884: <python baseline_mitbih.py> in cluster <leonhard> Done

Job <python baseline_mitbih.py> was submitted from host <lo-login-01> by user <mchevalley> in cluster <leonhard> at Sat Mar  7 18:03:11 2020
Job was executed on host(s) <lo-s4-034>, in queue <gpu.4h>, as user <mchevalley> in cluster <leonhard> at Sat Mar  7 18:03:39 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1> was used as the working directory.
Started at Sat Mar  7 18:03:39 2020
Terminated at Sat Mar  7 18:40:12 2020
Results reported at Sat Mar  7 18:40:12 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python baseline_mitbih.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4016.06 sec.
    Max Memory :                                 1482 MB
    Average Memory :                             1321.64 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               2614.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                19
    Run time :                                   2217 sec.
    Turnaround time :                            2221 sec.

The output (if any) follows:

2020-03-07 18:03:44.896332: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:44.898161: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:44.898176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-07 18:03:53.849239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-07 18:03:54.175161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-07 18:03:54.176531: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.177420: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.178137: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.179093: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.179970: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.181062: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.181710: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2020-03-07 18:03:54.181723: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-03-07 18:03:54.182061: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-07 18:03:54.189311: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199950000 Hz
2020-03-07 18:03:54.189450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ed76d4250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-07 18:03:54.189474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-07 18:03:54.421546: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ed7742750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-07 18:03:54.421580: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-07 18:03:54.421670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-07 18:03:54.421680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 187, 1)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 183, 16)           96        
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 179, 16)           1296      
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 89, 16)            0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 89, 16)            0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 87, 32)            1568      
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 85, 32)            3104      
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 42, 32)            0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 42, 32)            0         
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 40, 32)            3104      
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 38, 32)            3104      
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 19, 32)            0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 19, 32)            0         
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 17, 256)           24832     
_________________________________________________________________
conv1d_8 (Conv1D)            (None, 15, 256)           196864    
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 256)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                16448     
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3_mitbih (Dense)       (None, 5)                 325       
=================================================================
Total params: 254,901
Trainable params: 254,901
Non-trainable params: 0
_________________________________________________________________
Train on 78798 samples, validate on 8756 samples
Epoch 1/1000
 - 120s - loss: 0.3363 - acc: 0.9042 - val_loss: 0.2040 - val_acc: 0.9448

Epoch 00001: val_acc improved from -inf to 0.94484, saving model to baseline_cnn_mitbih.h5
Epoch 2/1000
 - 121s - loss: 0.1869 - acc: 0.9473 - val_loss: 0.1370 - val_acc: 0.9635

Epoch 00002: val_acc improved from 0.94484 to 0.96345, saving model to baseline_cnn_mitbih.h5
Epoch 3/1000
 - 120s - loss: 0.1451 - acc: 0.9596 - val_loss: 0.1171 - val_acc: 0.9703

Epoch 00003: val_acc improved from 0.96345 to 0.97031, saving model to baseline_cnn_mitbih.h5
Epoch 4/1000
 - 120s - loss: 0.1273 - acc: 0.9653 - val_loss: 0.1069 - val_acc: 0.9733

Epoch 00004: val_acc improved from 0.97031 to 0.97328, saving model to baseline_cnn_mitbih.h5
Epoch 5/1000
 - 120s - loss: 0.1143 - acc: 0.9682 - val_loss: 0.0883 - val_acc: 0.9753

Epoch 00005: val_acc improved from 0.97328 to 0.97533, saving model to baseline_cnn_mitbih.h5
Epoch 6/1000
 - 120s - loss: 0.1058 - acc: 0.9702 - val_loss: 0.0844 - val_acc: 0.9761

Epoch 00006: val_acc improved from 0.97533 to 0.97613, saving model to baseline_cnn_mitbih.h5
Epoch 7/1000
 - 120s - loss: 0.0967 - acc: 0.9732 - val_loss: 0.0730 - val_acc: 0.9794

Epoch 00007: val_acc improved from 0.97613 to 0.97944, saving model to baseline_cnn_mitbih.h5
Epoch 8/1000
 - 120s - loss: 0.0902 - acc: 0.9746 - val_loss: 0.0756 - val_acc: 0.9783

Epoch 00008: val_acc did not improve from 0.97944
Epoch 9/1000
 - 121s - loss: 0.0839 - acc: 0.9754 - val_loss: 0.0770 - val_acc: 0.9775

Epoch 00009: val_acc did not improve from 0.97944
Epoch 10/1000
 - 121s - loss: 0.0792 - acc: 0.9773 - val_loss: 0.0801 - val_acc: 0.9769

Epoch 00010: val_acc did not improve from 0.97944

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 11/1000
 - 120s - loss: 0.0590 - acc: 0.9827 - val_loss: 0.0558 - val_acc: 0.9852

Epoch 00011: val_acc improved from 0.97944 to 0.98515, saving model to baseline_cnn_mitbih.h5
Epoch 12/1000
 - 120s - loss: 0.0541 - acc: 0.9838 - val_loss: 0.0535 - val_acc: 0.9855

Epoch 00012: val_acc improved from 0.98515 to 0.98550, saving model to baseline_cnn_mitbih.h5
Epoch 13/1000
 - 120s - loss: 0.0502 - acc: 0.9846 - val_loss: 0.0514 - val_acc: 0.9860

Epoch 00013: val_acc improved from 0.98550 to 0.98595, saving model to baseline_cnn_mitbih.h5
Epoch 14/1000
 - 120s - loss: 0.0492 - acc: 0.9849 - val_loss: 0.0503 - val_acc: 0.9858

Epoch 00014: val_acc did not improve from 0.98595
Epoch 15/1000
 - 121s - loss: 0.0473 - acc: 0.9855 - val_loss: 0.0507 - val_acc: 0.9853

Epoch 00015: val_acc did not improve from 0.98595
Epoch 16/1000
 - 121s - loss: 0.0472 - acc: 0.9856 - val_loss: 0.0495 - val_acc: 0.9858

Epoch 00016: val_acc did not improve from 0.98595

Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 17/1000
 - 121s - loss: 0.0445 - acc: 0.9862 - val_loss: 0.0497 - val_acc: 0.9858

Epoch 00017: val_acc did not improve from 0.98595
Epoch 18/1000
 - 121s - loss: 0.0434 - acc: 0.9865 - val_loss: 0.0498 - val_acc: 0.9856
Using TensorFlow backend.

Epoch 00018: val_acc did not improve from 0.98595
Epoch 00018: early stopping
Test f1 score : 0.910659451128519 
Test accuracy score : 0.9830988488945733 
