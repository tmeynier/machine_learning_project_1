Sender: LSF System <lsfadmin@lo-s4-048>
Subject: Job 5279047: <python baseline_ptbdb.py> in cluster <leonhard> Done

Job <python baseline_ptbdb.py> was submitted from host <lo-login-01> by user <mchevalley> in cluster <leonhard> at Fri Mar 20 16:13:25 2020
Job was executed on host(s) <4*lo-s4-048>, in queue <gpu.24h>, as user <mchevalley> in cluster <leonhard> at Fri Mar 20 16:13:26 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1/baseline> was used as the working directory.
Started at Fri Mar 20 16:13:26 2020
Terminated at Fri Mar 20 16:15:24 2020
Results reported at Fri Mar 20 16:15:24 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python baseline_ptbdb.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   138.55 sec.
    Max Memory :                                 3201 MB
    Average Memory :                             2699.17 MB
    Total Requested Memory :                     32384.00 MB
    Delta Memory :                               29183.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                40
    Run time :                                   147 sec.
    Turnaround time :                            119 sec.

The output (if any) follows:

2020-03-20 16:13:32.546516: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-20 16:13:32.546852: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-20 16:13:32.546870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-20 16:13:36.760387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-20 16:13:36.823152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-20 16:13:36.825724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-20 16:13:36.849981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-20 16:13:36.864321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-20 16:13:36.871426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-20 16:13:36.896770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-20 16:13:36.904604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-20 16:13:36.966882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-20 16:13:36.972952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-20 16:13:36.973704: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-20 16:13:36.982889: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199850000 Hz
2020-03-20 16:13:36.983469: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6a7a9f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-20 16:13:36.983491: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-20 16:13:37.184078: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6b012e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-20 16:13:37.184125: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-20 16:13:37.188165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-20 16:13:37.188261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-20 16:13:37.188301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-20 16:13:37.188335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-20 16:13:37.188369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-20 16:13:37.188402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-20 16:13:37.188435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-20 16:13:37.188468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-20 16:13:37.194844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-20 16:13:37.196607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-20 16:13:37.201406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-20 16:13:37.201441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-20 16:13:37.201459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-20 16:13:37.209935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
2020-03-20 16:13:43.803531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-20 16:13:44.298055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-20 16:13:46.177229: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 187, 1)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 183, 16)           96        
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 179, 16)           1296      
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 89, 16)            0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 89, 16)            0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 87, 32)            1568      
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 85, 32)            3104      
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 42, 32)            0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 42, 32)            0         
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 40, 32)            3104      
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 38, 32)            3104      
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 19, 32)            0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 19, 32)            0         
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 17, 256)           24832     
_________________________________________________________________
conv1d_8 (Conv1D)            (None, 15, 256)           196864    
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 256)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                16448     
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3_ptbdb (Dense)        (None, 1)                 65        
=================================================================
Total params: 254,641
Trainable params: 254,641
Non-trainable params: 0
_________________________________________________________________
Train on 10476 samples, validate on 1165 samples
Epoch 1/1000
 - 7s - loss: 0.5032 - acc: 0.7543 - val_loss: 0.4993 - val_acc: 0.7442

Epoch 00001: val_acc improved from -inf to 0.74421, saving model to baseline_cnn_ptbdb.h5
Epoch 2/1000
 - 3s - loss: 0.3569 - acc: 0.8483 - val_loss: 0.2908 - val_acc: 0.8858

Epoch 00002: val_acc improved from 0.74421 to 0.88584, saving model to baseline_cnn_ptbdb.h5
Epoch 3/1000
 - 3s - loss: 0.2759 - acc: 0.8884 - val_loss: 0.2479 - val_acc: 0.8987

Epoch 00003: val_acc improved from 0.88584 to 0.89871, saving model to baseline_cnn_ptbdb.h5
Epoch 4/1000
 - 3s - loss: 0.2290 - acc: 0.9108 - val_loss: 0.2027 - val_acc: 0.9202

Epoch 00004: val_acc improved from 0.89871 to 0.92017, saving model to baseline_cnn_ptbdb.h5
Epoch 5/1000
 - 3s - loss: 0.2129 - acc: 0.9162 - val_loss: 0.1820 - val_acc: 0.9288

Epoch 00005: val_acc improved from 0.92017 to 0.92876, saving model to baseline_cnn_ptbdb.h5
Epoch 6/1000
 - 3s - loss: 0.1919 - acc: 0.9266 - val_loss: 0.1322 - val_acc: 0.9485

Epoch 00006: val_acc improved from 0.92876 to 0.94850, saving model to baseline_cnn_ptbdb.h5
Epoch 7/1000
 - 3s - loss: 0.1639 - acc: 0.9376 - val_loss: 0.1404 - val_acc: 0.9433

Epoch 00007: val_acc did not improve from 0.94850
Epoch 8/1000
 - 3s - loss: 0.1505 - acc: 0.9423 - val_loss: 0.1339 - val_acc: 0.9442

Epoch 00008: val_acc did not improve from 0.94850
Epoch 9/1000
 - 3s - loss: 0.1438 - acc: 0.9443 - val_loss: 0.1084 - val_acc: 0.9588

Epoch 00009: val_acc improved from 0.94850 to 0.95880, saving model to baseline_cnn_ptbdb.h5
Epoch 10/1000
 - 3s - loss: 0.1263 - acc: 0.9540 - val_loss: 0.0997 - val_acc: 0.9631

Epoch 00010: val_acc improved from 0.95880 to 0.96309, saving model to baseline_cnn_ptbdb.h5
Epoch 11/1000
 - 3s - loss: 0.1116 - acc: 0.9563 - val_loss: 0.0856 - val_acc: 0.9665

Epoch 00011: val_acc improved from 0.96309 to 0.96652, saving model to baseline_cnn_ptbdb.h5
Epoch 12/1000
 - 3s - loss: 0.1050 - acc: 0.9599 - val_loss: 0.0898 - val_acc: 0.9691

Epoch 00012: val_acc improved from 0.96652 to 0.96910, saving model to baseline_cnn_ptbdb.h5
Epoch 13/1000
 - 3s - loss: 0.0978 - acc: 0.9631 - val_loss: 0.0696 - val_acc: 0.9768

Epoch 00013: val_acc improved from 0.96910 to 0.97682, saving model to baseline_cnn_ptbdb.h5
Epoch 14/1000
 - 3s - loss: 0.0943 - acc: 0.9651 - val_loss: 0.0858 - val_acc: 0.9682

Epoch 00014: val_acc did not improve from 0.97682
Epoch 15/1000
 - 3s - loss: 0.0830 - acc: 0.9698 - val_loss: 0.1057 - val_acc: 0.9571

Epoch 00015: val_acc did not improve from 0.97682
Epoch 16/1000
 - 3s - loss: 0.0795 - acc: 0.9703 - val_loss: 0.0592 - val_acc: 0.9803

Epoch 00016: val_acc improved from 0.97682 to 0.98026, saving model to baseline_cnn_ptbdb.h5
Epoch 17/1000
 - 3s - loss: 0.0749 - acc: 0.9712 - val_loss: 0.0820 - val_acc: 0.9742

Epoch 00017: val_acc did not improve from 0.98026
Epoch 18/1000
 - 3s - loss: 0.0714 - acc: 0.9747 - val_loss: 0.0637 - val_acc: 0.9751

Epoch 00018: val_acc did not improve from 0.98026
Epoch 19/1000
 - 3s - loss: 0.0664 - acc: 0.9750 - val_loss: 0.0585 - val_acc: 0.9785

Epoch 00019: val_acc did not improve from 0.98026

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 20/1000
 - 3s - loss: 0.0422 - acc: 0.9851 - val_loss: 0.0451 - val_acc: 0.9837

Epoch 00020: val_acc improved from 0.98026 to 0.98369, saving model to baseline_cnn_ptbdb.h5
Epoch 21/1000
 - 3s - loss: 0.0363 - acc: 0.9863 - val_loss: 0.0417 - val_acc: 0.9871

Epoch 00021: val_acc improved from 0.98369 to 0.98712, saving model to baseline_cnn_ptbdb.h5
Epoch 22/1000
 - 3s - loss: 0.0318 - acc: 0.9877 - val_loss: 0.0400 - val_acc: 0.9845

Epoch 00022: val_acc did not improve from 0.98712
Epoch 23/1000
 - 3s - loss: 0.0290 - acc: 0.9897 - val_loss: 0.0376 - val_acc: 0.9880

Epoch 00023: val_acc improved from 0.98712 to 0.98798, saving model to baseline_cnn_ptbdb.h5
Epoch 24/1000
 - 3s - loss: 0.0315 - acc: 0.9881 - val_loss: 0.0399 - val_acc: 0.9863

Epoch 00024: val_acc did not improve from 0.98798
Epoch 25/1000
 - 3s - loss: 0.0304 - acc: 0.9888 - val_loss: 0.0366 - val_acc: 0.9888

Epoch 00025: val_acc improved from 0.98798 to 0.98884, saving model to baseline_cnn_ptbdb.h5
Epoch 26/1000
 - 3s - loss: 0.0256 - acc: 0.9908 - val_loss: 0.0346 - val_acc: 0.9914

Epoch 00026: val_acc improved from 0.98884 to 0.99142, saving model to baseline_cnn_ptbdb.h5
Epoch 27/1000
 - 3s - loss: 0.0278 - acc: 0.9894 - val_loss: 0.0430 - val_acc: 0.9880

Epoch 00027: val_acc did not improve from 0.99142
Epoch 28/1000
 - 3s - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0343 - val_acc: 0.9897

Epoch 00028: val_acc did not improve from 0.99142
Epoch 29/1000
 - 3s - loss: 0.0219 - acc: 0.9926 - val_loss: 0.0353 - val_acc: 0.9914

Epoch 00029: val_acc did not improve from 0.99142

Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 30/1000
 - 3s - loss: 0.0257 - acc: 0.9907 - val_loss: 0.0334 - val_acc: 0.9923

Epoch 00030: val_acc improved from 0.99142 to 0.99227, saving model to baseline_cnn_ptbdb.h5
Epoch 31/1000
 - 3s - loss: 0.0221 - acc: 0.9913 - val_loss: 0.0334 - val_acc: 0.9923

Epoch 00031: val_acc did not improve from 0.99227
Epoch 32/1000
 - 3s - loss: 0.0206 - acc: 0.9924 - val_loss: 0.0332 - val_acc: 0.9923

Epoch 00032: val_acc did not improve from 0.99227
Epoch 33/1000
 - 3s - loss: 0.0236 - acc: 0.9918 - val_loss: 0.0345 - val_acc: 0.9923

Epoch 00033: val_acc did not improve from 0.99227

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Epoch 34/1000
 - 3s - loss: 0.0215 - acc: 0.9920 - val_loss: 0.0344 - val_acc: 0.9923

Epoch 00034: val_acc did not improve from 0.99227
Epoch 35/1000
 - 3s - loss: 0.0223 - acc: 0.9923 - val_loss: 0.0343 - val_acc: 0.9923
Using TensorFlow backend.

Epoch 00035: val_acc did not improve from 0.99227
Epoch 00035: early stopping
Test f1 score : 0.9954858636255642 
Test accuracy score : 0.9934730333218825 
Test auroc score : 0.9909183554658051 
Test auprc score : 0.9933981750817675 
