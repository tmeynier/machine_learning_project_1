Sender: LSF System <lsfadmin@lo-s4-038>
Subject: Job 5273891: <python residual_blocks_mit.py> in cluster <leonhard> Done

Job <python residual_blocks_mit.py> was submitted from host <lo-login-02> by user <mchevalley> in cluster <leonhard> at Fri Mar 20 12:09:40 2020
Job was executed on host(s) <8*lo-s4-038>, in queue <gpu.24h>, as user <mchevalley> in cluster <leonhard> at Fri Mar 20 12:15:21 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1/residual_network> was used as the working directory.
Started at Fri Mar 20 12:15:21 2020
Terminated at Fri Mar 20 12:25:38 2020
Results reported at Fri Mar 20 12:25:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python residual_blocks_mit.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   707.16 sec.
    Max Memory :                                 3983 MB
    Average Memory :                             3797.38 MB
    Total Requested Memory :                     64768.00 MB
    Delta Memory :                               60785.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                64
    Run time :                                   617 sec.
    Turnaround time :                            958 sec.

The output (if any) follows:

2020-03-20 12:15:27.083935: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-20 12:15:27.084422: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-20 12:15:27.084436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-20 12:15:36.322798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-20 12:15:36.409480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-20 12:15:36.412183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-20 12:15:36.439066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-20 12:15:36.455920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-20 12:15:36.466534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-20 12:15:36.496062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-20 12:15:36.505252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-20 12:15:36.562870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-20 12:15:36.570663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-20 12:15:36.571587: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-20 12:15:36.581709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199930000 Hz
2020-03-20 12:15:36.582590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4614190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-20 12:15:36.582613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-20 12:15:36.811377: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x467a260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-20 12:15:36.811446: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-20 12:15:36.816160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-20 12:15:36.816240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-20 12:15:36.816277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-20 12:15:36.816320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-20 12:15:36.816351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-20 12:15:36.816381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-20 12:15:36.816411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-20 12:15:36.816442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-20 12:15:36.826275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-20 12:15:36.827709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-20 12:15:36.833768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-20 12:15:36.833799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-20 12:15:36.833817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-20 12:15:36.843987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
2020-03-20 12:15:42.821318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-20 12:15:43.277431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-20 12:15:44.958089: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 187, 1)       0                                            
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 183, 32)      192         input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 183, 32)      5152        conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 183, 32)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 183, 32)      5152        activation_1[0][0]               
__________________________________________________________________________________________________
add_1 (Add)                     (None, 183, 32)      0           conv1d_3[0][0]                   
                                                                 conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 183, 32)      0           add_1[0][0]                      
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 90, 32)       0           activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 90, 32)       5152        max_pooling1d_1[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 90, 32)       0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 90, 32)       5152        activation_3[0][0]               
__________________________________________________________________________________________________
add_2 (Add)                     (None, 90, 32)       0           conv1d_5[0][0]                   
                                                                 max_pooling1d_1[0][0]            
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 90, 32)       0           add_2[0][0]                      
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 43, 32)       0           activation_4[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 43, 32)       5152        max_pooling1d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 43, 32)       0           conv1d_6[0][0]                   
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 43, 32)       5152        activation_5[0][0]               
__________________________________________________________________________________________________
add_3 (Add)                     (None, 43, 32)       0           conv1d_7[0][0]                   
                                                                 max_pooling1d_2[0][0]            
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 43, 32)       0           add_3[0][0]                      
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 20, 32)       0           activation_6[0][0]               
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 20, 32)       5152        max_pooling1d_3[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 32)       0           conv1d_8[0][0]                   
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 20, 32)       5152        activation_7[0][0]               
__________________________________________________________________________________________________
add_4 (Add)                     (None, 20, 32)       0           conv1d_9[0][0]                   
                                                                 max_pooling1d_3[0][0]            
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 32)       0           add_4[0][0]                      
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 8, 32)        0           activation_8[0][0]               
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 8, 32)        5152        max_pooling1d_4[0][0]            
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 8, 32)        0           conv1d_10[0][0]                  
__________________________________________________________________________________________________
conv1d_11 (Conv1D)              (None, 8, 32)        5152        activation_9[0][0]               
__________________________________________________________________________________________________
add_5 (Add)                     (None, 8, 32)        0           conv1d_11[0][0]                  
                                                                 max_pooling1d_4[0][0]            
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 8, 32)        0           add_5[0][0]                      
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 2, 32)        0           activation_10[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           max_pooling1d_5[0][0]            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 32)           2080        flatten_1[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 32)           1056        activation_11[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 5)            165         dense_2[0][0]                    
__________________________________________________________________________________________________
softmax_1 (Softmax)             (None, 5)            0           dense_3[0][0]                    
==================================================================================================
Total params: 55,013
Trainable params: 55,013
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 78798 samples, validate on 8756 samples
Epoch 1/1000
 - 36s - loss: 0.1776 - acc: 0.9497 - val_loss: 0.1120 - val_acc: 0.9695

Epoch 00001: val_acc improved from -inf to 0.96951, saving model to resnet_mitbih.h5
Epoch 2/1000
 - 31s - loss: 0.0936 - acc: 0.9740 - val_loss: 0.0795 - val_acc: 0.9778

Epoch 00002: val_acc improved from 0.96951 to 0.97784, saving model to resnet_mitbih.h5
Epoch 3/1000
 - 30s - loss: 0.0760 - acc: 0.9782 - val_loss: 0.0950 - val_acc: 0.9759

Epoch 00003: val_acc did not improve from 0.97784
Epoch 4/1000
 - 32s - loss: 0.0676 - acc: 0.9807 - val_loss: 0.0611 - val_acc: 0.9834

Epoch 00004: val_acc improved from 0.97784 to 0.98344, saving model to resnet_mitbih.h5
Epoch 5/1000
 - 30s - loss: 0.0615 - acc: 0.9825 - val_loss: 0.0642 - val_acc: 0.9817

Epoch 00005: val_acc did not improve from 0.98344
Epoch 6/1000
 - 28s - loss: 0.0551 - acc: 0.9839 - val_loss: 0.0618 - val_acc: 0.9815

Epoch 00006: val_acc did not improve from 0.98344
Epoch 7/1000
 - 31s - loss: 0.0538 - acc: 0.9841 - val_loss: 0.0740 - val_acc: 0.9776

Epoch 00007: val_acc did not improve from 0.98344

Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 8/1000
 - 29s - loss: 0.0335 - acc: 0.9896 - val_loss: 0.0444 - val_acc: 0.9879

Epoch 00008: val_acc improved from 0.98344 to 0.98789, saving model to resnet_mitbih.h5
Epoch 9/1000
 - 31s - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0424 - val_acc: 0.9886

Epoch 00009: val_acc improved from 0.98789 to 0.98858, saving model to resnet_mitbih.h5
Epoch 10/1000
 - 31s - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0417 - val_acc: 0.9884

Epoch 00010: val_acc did not improve from 0.98858
Epoch 11/1000
 - 32s - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0441 - val_acc: 0.9885

Epoch 00011: val_acc did not improve from 0.98858
Epoch 12/1000
 - 30s - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0467 - val_acc: 0.9884

Epoch 00012: val_acc did not improve from 0.98858

Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 13/1000
 - 31s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0454 - val_acc: 0.9892

Epoch 00013: val_acc improved from 0.98858 to 0.98915, saving model to resnet_mitbih.h5
Epoch 14/1000
 - 32s - loss: 0.0129 - acc: 0.9963 - val_loss: 0.0458 - val_acc: 0.9894

Epoch 00014: val_acc improved from 0.98915 to 0.98938, saving model to resnet_mitbih.h5
Epoch 15/1000
 - 31s - loss: 0.0125 - acc: 0.9964 - val_loss: 0.0465 - val_acc: 0.9893

Epoch 00015: val_acc did not improve from 0.98938
Epoch 16/1000
 - 31s - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0467 - val_acc: 0.9893

Epoch 00016: val_acc did not improve from 0.98938
Epoch 17/1000
 - 31s - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0472 - val_acc: 0.9892

Epoch 00017: val_acc did not improve from 0.98938

Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Epoch 18/1000
 - 32s - loss: 0.0113 - acc: 0.9968 - val_loss: 0.0472 - val_acc: 0.9892

Epoch 00018: val_acc did not improve from 0.98938
Epoch 19/1000
 - 32s - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0472 - val_acc: 0.9894
Using TensorFlow backend.

Epoch 00019: val_acc did not improve from 0.98938
Epoch 00019: early stopping
Test f1 score : 0.9284667701166984 
Test accuracy score : 0.9877580851452585 
