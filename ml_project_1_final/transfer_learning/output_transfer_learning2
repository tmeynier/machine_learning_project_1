Sender: LSF System <lsfadmin@lo-s4-042>
Subject: Job 5215773: <python transfer_learning2.py> in cluster <leonhard> Done

Job <python transfer_learning2.py> was submitted from host <lo-login-01> by user <mchevalley> in cluster <leonhard> at Sun Mar 15 18:25:25 2020
Job was executed on host(s) <4*lo-s4-042>, in queue <gpu.24h>, as user <mchevalley> in cluster <leonhard> at Sun Mar 15 18:25:49 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1/transfer_learning> was used as the working directory.
Started at Sun Mar 15 18:25:49 2020
Terminated at Sun Mar 15 18:47:44 2020
Results reported at Sun Mar 15 18:47:44 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python transfer_learning2.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2310.55 sec.
    Max Memory :                                 1237 MB
    Average Memory :                             1207.57 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15147.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                39
    Run time :                                   1336 sec.
    Turnaround time :                            1339 sec.

The output (if any) follows:

2020-03-15 18:25:54.367069: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-15 18:25:54.367403: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-15 18:25:54.367419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-15 18:25:57.219979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-15 18:25:57.307585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-15 18:25:57.308861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-15 18:25:57.312793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-15 18:25:57.316224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-15 18:25:57.317200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-15 18:25:57.320667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-15 18:25:57.322595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-15 18:25:57.329215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-15 18:25:57.336082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-15 18:25:57.336822: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-15 18:25:57.347268: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199950000 Hz
2020-03-15 18:25:57.347825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5775850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-15 18:25:57.347848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-15 18:25:57.569033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57fc150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-15 18:25:57.569079: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-15 18:25:57.574718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-15 18:25:57.574784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-15 18:25:57.574809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-15 18:25:57.574830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-15 18:25:57.574849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-15 18:25:57.574869: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-15 18:25:57.574888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-15 18:25:57.574909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-15 18:25:57.583353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-15 18:25:57.583411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-15 18:25:57.586753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-15 18:25:57.586774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-15 18:25:57.586787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-15 18:25:57.595557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
2020-03-15 18:26:03.543987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1_input (InputLay (None, 187, 1)            0         
_________________________________________________________________
simple_rnn_1 (SimpleRNN)     (None, 187, 256)          66048     
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 124)               47244     
_________________________________________________________________
dropout_1 (Dropout)          (None, 124)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 125       
=================================================================
Total params: 113,417
Trainable params: 113,417
Non-trainable params: 0
_________________________________________________________________
Train on 10476 samples, validate on 1165 samples
Epoch 1/1000
 - 31s - loss: 0.5287 - acc: 0.7259 - val_loss: 0.5853 - val_acc: 0.7064

Epoch 00001: val_acc improved from -inf to 0.70644, saving model to transfert_learning2.h5
Epoch 2/1000
 - 30s - loss: 0.4935 - acc: 0.7490 - val_loss: 0.5475 - val_acc: 0.7030

Epoch 00002: val_acc did not improve from 0.70644
Epoch 3/1000
 - 31s - loss: 0.4786 - acc: 0.7508 - val_loss: 0.4513 - val_acc: 0.7871

Epoch 00003: val_acc improved from 0.70644 to 0.78712, saving model to transfert_learning2.h5
Epoch 4/1000
 - 31s - loss: 0.4425 - acc: 0.7731 - val_loss: 0.3963 - val_acc: 0.8094

Epoch 00004: val_acc improved from 0.78712 to 0.80944, saving model to transfert_learning2.h5
Epoch 5/1000
 - 31s - loss: 0.4091 - acc: 0.7988 - val_loss: 0.4174 - val_acc: 0.7948

Epoch 00005: val_acc did not improve from 0.80944
Epoch 6/1000
 - 31s - loss: 0.4110 - acc: 0.7986 - val_loss: 0.4197 - val_acc: 0.7717

Epoch 00006: val_acc did not improve from 0.80944
Epoch 7/1000
 - 31s - loss: 0.3967 - acc: 0.8015 - val_loss: 0.5220 - val_acc: 0.7863

Epoch 00007: val_acc did not improve from 0.80944

Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 8/1000
 - 31s - loss: 0.3452 - acc: 0.8422 - val_loss: 0.3372 - val_acc: 0.8541

Epoch 00008: val_acc improved from 0.80944 to 0.85408, saving model to transfert_learning2.h5
Epoch 9/1000
 - 31s - loss: 0.3267 - acc: 0.8510 - val_loss: 0.3290 - val_acc: 0.8567

Epoch 00009: val_acc improved from 0.85408 to 0.85665, saving model to transfert_learning2.h5
Epoch 10/1000
 - 31s - loss: 0.3217 - acc: 0.8572 - val_loss: 0.3219 - val_acc: 0.8584

Epoch 00010: val_acc improved from 0.85665 to 0.85837, saving model to transfert_learning2.h5
Epoch 11/1000
 - 31s - loss: 0.3157 - acc: 0.8653 - val_loss: 0.3262 - val_acc: 0.8481

Epoch 00011: val_acc did not improve from 0.85837
Epoch 12/1000
 - 31s - loss: 0.3080 - acc: 0.8679 - val_loss: 0.3102 - val_acc: 0.8558

Epoch 00012: val_acc did not improve from 0.85837
Epoch 13/1000
 - 31s - loss: 0.3052 - acc: 0.8665 - val_loss: 0.3106 - val_acc: 0.8601

Epoch 00013: val_acc improved from 0.85837 to 0.86009, saving model to transfert_learning2.h5
Epoch 14/1000
 - 31s - loss: 0.3004 - acc: 0.8708 - val_loss: 0.3067 - val_acc: 0.8661

Epoch 00014: val_acc improved from 0.86009 to 0.86609, saving model to transfert_learning2.h5
Epoch 15/1000
 - 31s - loss: 0.2900 - acc: 0.8793 - val_loss: 0.3079 - val_acc: 0.8695

Epoch 00015: val_acc improved from 0.86609 to 0.86953, saving model to transfert_learning2.h5
Epoch 16/1000
 - 31s - loss: 0.2876 - acc: 0.8790 - val_loss: 0.3017 - val_acc: 0.8730

Epoch 00016: val_acc improved from 0.86953 to 0.87296, saving model to transfert_learning2.h5
Epoch 17/1000
 - 31s - loss: 0.2837 - acc: 0.8807 - val_loss: 0.3032 - val_acc: 0.8721

Epoch 00017: val_acc did not improve from 0.87296
Epoch 18/1000
 - 32s - loss: 0.2794 - acc: 0.8833 - val_loss: 0.2914 - val_acc: 0.8781

Epoch 00018: val_acc improved from 0.87296 to 0.87811, saving model to transfert_learning2.h5
Epoch 19/1000
 - 31s - loss: 0.2719 - acc: 0.8906 - val_loss: 0.2857 - val_acc: 0.8712

Epoch 00019: val_acc did not improve from 0.87811
Epoch 20/1000
 - 31s - loss: 0.2705 - acc: 0.8877 - val_loss: 0.2981 - val_acc: 0.8755

Epoch 00020: val_acc did not improve from 0.87811
Epoch 21/1000
 - 31s - loss: 0.2684 - acc: 0.8895 - val_loss: 0.2891 - val_acc: 0.8833

Epoch 00021: val_acc improved from 0.87811 to 0.88326, saving model to transfert_learning2.h5
Epoch 22/1000
 - 30s - loss: 0.2648 - acc: 0.8903 - val_loss: 0.2754 - val_acc: 0.8910

Epoch 00022: val_acc improved from 0.88326 to 0.89099, saving model to transfert_learning2.h5
Epoch 23/1000
 - 31s - loss: 0.2560 - acc: 0.8906 - val_loss: 0.2694 - val_acc: 0.8850

Epoch 00023: val_acc did not improve from 0.89099
Epoch 24/1000
 - 31s - loss: 0.2462 - acc: 0.8996 - val_loss: 0.2756 - val_acc: 0.8781

Epoch 00024: val_acc did not improve from 0.89099
Epoch 25/1000
 - 30s - loss: 0.2469 - acc: 0.9007 - val_loss: 0.2691 - val_acc: 0.8867

Epoch 00025: val_acc did not improve from 0.89099

Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 26/1000
 - 30s - loss: 0.2285 - acc: 0.9063 - val_loss: 0.2539 - val_acc: 0.8953

Epoch 00026: val_acc improved from 0.89099 to 0.89528, saving model to transfert_learning2.h5
Epoch 27/1000
 - 31s - loss: 0.2275 - acc: 0.9079 - val_loss: 0.2562 - val_acc: 0.9004

Epoch 00027: val_acc improved from 0.89528 to 0.90043, saving model to transfert_learning2.h5
Epoch 28/1000
 - 31s - loss: 0.2252 - acc: 0.9094 - val_loss: 0.2541 - val_acc: 0.8918

Epoch 00028: val_acc did not improve from 0.90043
Epoch 29/1000
 - 31s - loss: 0.2218 - acc: 0.9100 - val_loss: 0.2550 - val_acc: 0.8961

Epoch 00029: val_acc did not improve from 0.90043
Epoch 30/1000
 - 31s - loss: 0.2263 - acc: 0.9089 - val_loss: 0.2508 - val_acc: 0.8987

Epoch 00030: val_acc did not improve from 0.90043

Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 31/1000
 - 30s - loss: 0.2238 - acc: 0.9085 - val_loss: 0.2505 - val_acc: 0.8979

Epoch 00031: val_acc did not improve from 0.90043
Epoch 32/1000
 - 30s - loss: 0.2215 - acc: 0.9086 - val_loss: 0.2507 - val_acc: 0.8979

Epoch 00032: val_acc did not improve from 0.90043
Epoch 33/1000
 - 30s - loss: 0.2210 - acc: 0.9118 - val_loss: 0.2508 - val_acc: 0.8987

Epoch 00033: val_acc did not improve from 0.90043

Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 34/1000
 - 30s - loss: 0.2201 - acc: 0.9108 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00034: val_acc did not improve from 0.90043
Epoch 35/1000
 - 30s - loss: 0.2225 - acc: 0.9107 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00035: val_acc did not improve from 0.90043
Epoch 36/1000
 - 31s - loss: 0.2203 - acc: 0.9119 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00036: val_acc did not improve from 0.90043

Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 37/1000
 - 31s - loss: 0.2221 - acc: 0.9112 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00037: val_acc did not improve from 0.90043
Epoch 38/1000
 - 31s - loss: 0.2214 - acc: 0.9124 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00038: val_acc did not improve from 0.90043
Epoch 39/1000
 - 31s - loss: 0.2202 - acc: 0.9115 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00039: val_acc did not improve from 0.90043

Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 40/1000
 - 31s - loss: 0.2200 - acc: 0.9121 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00040: val_acc did not improve from 0.90043
Epoch 41/1000
 - 31s - loss: 0.2204 - acc: 0.9134 - val_loss: 0.2509 - val_acc: 0.8979

Epoch 00041: val_acc did not improve from 0.90043
Epoch 42/1000
 - 31s - loss: 0.2217 - acc: 0.9119 - val_loss: 0.2509 - val_acc: 0.8979
Using TensorFlow backend.
transfer_learning2.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model2 = Model(inputs = new_model.inputs, output = dense_1)

Epoch 00042: val_acc did not improve from 0.90043

Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.
Epoch 00042: early stopping
Test f1 score : 0.8741803967967408 
Test accuracy score : 0.8990037787701821 
