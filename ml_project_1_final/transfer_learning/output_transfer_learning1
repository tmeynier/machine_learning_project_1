Sender: LSF System <lsfadmin@lo-s4-038>
Subject: Job 5215769: <python transfer_learning1.py> in cluster <leonhard> Done

Job <python transfer_learning1.py> was submitted from host <lo-login-01> by user <mchevalley> in cluster <leonhard> at Sun Mar 15 18:06:37 2020
Job was executed on host(s) <4*lo-s4-038>, in queue <gpu.24h>, as user <mchevalley> in cluster <leonhard> at Sun Mar 15 18:06:50 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1/transfer_learning> was used as the working directory.
Started at Sun Mar 15 18:06:50 2020
Terminated at Sun Mar 15 18:07:45 2020
Results reported at Sun Mar 15 18:07:45 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python transfer_learning1.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   65.00 sec.
    Max Memory :                                 2374 MB
    Average Memory :                             1845.25 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               14010.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                39
    Run time :                                   81 sec.
    Turnaround time :                            68 sec.

The output (if any) follows:

2020-03-15 18:06:56.489985: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-15 18:06:56.490406: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-15 18:06:56.490423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-15 18:06:59.597503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-15 18:06:59.679900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-15 18:06:59.683150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-15 18:06:59.712665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-15 18:06:59.730344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-15 18:06:59.737861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-15 18:06:59.768306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-15 18:06:59.778206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-15 18:06:59.836054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-15 18:06:59.849207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-15 18:06:59.850150: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-15 18:06:59.863224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199930000 Hz
2020-03-15 18:06:59.863846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a1ca40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-15 18:06:59.863875: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-15 18:07:00.102080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5aa3340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-15 18:07:00.102137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-03-15 18:07:00.107858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-03-15 18:07:00.107944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-15 18:07:00.107983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-15 18:07:00.108040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-15 18:07:00.108073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-15 18:07:00.108105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-15 18:07:00.108137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-15 18:07:00.108169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-15 18:07:00.119847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-15 18:07:00.121377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-15 18:07:00.126495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-15 18:07:00.126523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-15 18:07:00.126540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-15 18:07:00.135956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
2020-03-15 18:07:04.872887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 124)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 124)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 125       
=================================================================
Total params: 125
Trainable params: 125
Non-trainable params: 0
_________________________________________________________________
Train on 10476 samples, validate on 1165 samples
Epoch 1/1000
 - 1s - loss: 0.8686 - acc: 0.4107 - val_loss: 0.7634 - val_acc: 0.4369

Epoch 00001: val_acc improved from -inf to 0.43691, saving model to transfert_learning1.h5
Epoch 2/1000
 - 0s - loss: 0.7258 - acc: 0.5181 - val_loss: 0.6823 - val_acc: 0.5536

Epoch 00002: val_acc improved from 0.43691 to 0.55365, saving model to transfert_learning1.h5
Epoch 3/1000
 - 0s - loss: 0.6627 - acc: 0.6069 - val_loss: 0.6417 - val_acc: 0.6206

Epoch 00003: val_acc improved from 0.55365 to 0.62060, saving model to transfert_learning1.h5
Epoch 4/1000
 - 0s - loss: 0.6230 - acc: 0.6528 - val_loss: 0.6140 - val_acc: 0.6472

Epoch 00004: val_acc improved from 0.62060 to 0.64721, saving model to transfert_learning1.h5
Epoch 5/1000
 - 0s - loss: 0.5978 - acc: 0.6784 - val_loss: 0.5923 - val_acc: 0.6712

Epoch 00005: val_acc improved from 0.64721 to 0.67124, saving model to transfert_learning1.h5
Epoch 6/1000
 - 0s - loss: 0.5782 - acc: 0.6950 - val_loss: 0.5751 - val_acc: 0.6884

Epoch 00006: val_acc improved from 0.67124 to 0.68841, saving model to transfert_learning1.h5
Epoch 7/1000
 - 0s - loss: 0.5623 - acc: 0.7098 - val_loss: 0.5607 - val_acc: 0.6987

Epoch 00007: val_acc improved from 0.68841 to 0.69871, saving model to transfert_learning1.h5
Epoch 8/1000
 - 0s - loss: 0.5451 - acc: 0.7185 - val_loss: 0.5488 - val_acc: 0.7099

Epoch 00008: val_acc improved from 0.69871 to 0.70987, saving model to transfert_learning1.h5
Epoch 9/1000
 - 0s - loss: 0.5357 - acc: 0.7245 - val_loss: 0.5400 - val_acc: 0.7176

Epoch 00009: val_acc improved from 0.70987 to 0.71760, saving model to transfert_learning1.h5
Epoch 10/1000
 - 0s - loss: 0.5273 - acc: 0.7314 - val_loss: 0.5321 - val_acc: 0.7185

Epoch 00010: val_acc improved from 0.71760 to 0.71845, saving model to transfert_learning1.h5
Epoch 11/1000
 - 0s - loss: 0.5182 - acc: 0.7404 - val_loss: 0.5257 - val_acc: 0.7167

Epoch 00011: val_acc did not improve from 0.71845
Epoch 12/1000
 - 0s - loss: 0.5134 - acc: 0.7374 - val_loss: 0.5208 - val_acc: 0.7210

Epoch 00012: val_acc improved from 0.71845 to 0.72103, saving model to transfert_learning1.h5
Epoch 13/1000
 - 0s - loss: 0.5088 - acc: 0.7458 - val_loss: 0.5170 - val_acc: 0.7253

Epoch 00013: val_acc improved from 0.72103 to 0.72532, saving model to transfert_learning1.h5
Epoch 14/1000
 - 0s - loss: 0.5042 - acc: 0.7425 - val_loss: 0.5123 - val_acc: 0.7330

Epoch 00014: val_acc improved from 0.72532 to 0.73305, saving model to transfert_learning1.h5
Epoch 15/1000
 - 0s - loss: 0.5002 - acc: 0.7483 - val_loss: 0.5092 - val_acc: 0.7382

Epoch 00015: val_acc improved from 0.73305 to 0.73820, saving model to transfert_learning1.h5
Epoch 16/1000
 - 0s - loss: 0.4954 - acc: 0.7497 - val_loss: 0.5068 - val_acc: 0.7373

Epoch 00016: val_acc did not improve from 0.73820
Epoch 17/1000
 - 0s - loss: 0.4940 - acc: 0.7530 - val_loss: 0.5045 - val_acc: 0.7442

Epoch 00017: val_acc improved from 0.73820 to 0.74421, saving model to transfert_learning1.h5
Epoch 18/1000
 - 0s - loss: 0.4908 - acc: 0.7549 - val_loss: 0.5024 - val_acc: 0.7494

Epoch 00018: val_acc improved from 0.74421 to 0.74936, saving model to transfert_learning1.h5
Epoch 19/1000
 - 0s - loss: 0.4879 - acc: 0.7573 - val_loss: 0.5012 - val_acc: 0.7502

Epoch 00019: val_acc improved from 0.74936 to 0.75021, saving model to transfert_learning1.h5
Epoch 20/1000
 - 0s - loss: 0.4849 - acc: 0.7584 - val_loss: 0.4993 - val_acc: 0.7528

Epoch 00020: val_acc improved from 0.75021 to 0.75279, saving model to transfert_learning1.h5
Epoch 21/1000
 - 0s - loss: 0.4856 - acc: 0.7612 - val_loss: 0.4978 - val_acc: 0.7562

Epoch 00021: val_acc improved from 0.75279 to 0.75622, saving model to transfert_learning1.h5
Epoch 22/1000
 - 0s - loss: 0.4822 - acc: 0.7631 - val_loss: 0.4970 - val_acc: 0.7571

Epoch 00022: val_acc improved from 0.75622 to 0.75708, saving model to transfert_learning1.h5
Epoch 23/1000
 - 0s - loss: 0.4822 - acc: 0.7630 - val_loss: 0.4949 - val_acc: 0.7597

Epoch 00023: val_acc improved from 0.75708 to 0.75966, saving model to transfert_learning1.h5
Epoch 24/1000
 - 0s - loss: 0.4825 - acc: 0.7603 - val_loss: 0.4940 - val_acc: 0.7605

Epoch 00024: val_acc improved from 0.75966 to 0.76052, saving model to transfert_learning1.h5
Epoch 25/1000
 - 0s - loss: 0.4821 - acc: 0.7622 - val_loss: 0.4933 - val_acc: 0.7605

Epoch 00025: val_acc did not improve from 0.76052
Epoch 26/1000
 - 0s - loss: 0.4777 - acc: 0.7655 - val_loss: 0.4925 - val_acc: 0.7614

Epoch 00026: val_acc improved from 0.76052 to 0.76137, saving model to transfert_learning1.h5
Epoch 27/1000
 - 0s - loss: 0.4769 - acc: 0.7648 - val_loss: 0.4921 - val_acc: 0.7614

Epoch 00027: val_acc did not improve from 0.76137
Epoch 28/1000
 - 0s - loss: 0.4767 - acc: 0.7681 - val_loss: 0.4917 - val_acc: 0.7597

Epoch 00028: val_acc did not improve from 0.76137
Epoch 29/1000
 - 0s - loss: 0.4766 - acc: 0.7672 - val_loss: 0.4904 - val_acc: 0.7648

Epoch 00029: val_acc improved from 0.76137 to 0.76481, saving model to transfert_learning1.h5
Epoch 30/1000
 - 0s - loss: 0.4715 - acc: 0.7682 - val_loss: 0.4904 - val_acc: 0.7631

Epoch 00030: val_acc did not improve from 0.76481
Epoch 31/1000
 - 0s - loss: 0.4738 - acc: 0.7694 - val_loss: 0.4901 - val_acc: 0.7631

Epoch 00031: val_acc did not improve from 0.76481
Epoch 32/1000
 - 0s - loss: 0.4716 - acc: 0.7699 - val_loss: 0.4888 - val_acc: 0.7639

Epoch 00032: val_acc did not improve from 0.76481

Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 33/1000
 - 0s - loss: 0.4721 - acc: 0.7697 - val_loss: 0.4888 - val_acc: 0.7631

Epoch 00033: val_acc did not improve from 0.76481
Epoch 34/1000
 - 0s - loss: 0.4723 - acc: 0.7702 - val_loss: 0.4888 - val_acc: 0.7631

Epoch 00034: val_acc did not improve from 0.76481
Epoch 35/1000
 - 0s - loss: 0.4725 - acc: 0.7700 - val_loss: 0.4888 - val_acc: 0.7639

Epoch 00035: val_acc did not improve from 0.76481

Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 36/1000
 - 0s - loss: 0.4726 - acc: 0.7643 - val_loss: 0.4888 - val_acc: 0.7639

Epoch 00036: val_acc did not improve from 0.76481
Epoch 37/1000
 - 0s - loss: 0.4725 - acc: 0.7663 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00037: val_acc did not improve from 0.76481
Epoch 38/1000
 - 0s - loss: 0.4736 - acc: 0.7710 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00038: val_acc did not improve from 0.76481

Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 39/1000
 - 0s - loss: 0.4730 - acc: 0.7665 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00039: val_acc did not improve from 0.76481
Epoch 40/1000
 - 0s - loss: 0.4761 - acc: 0.7676 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00040: val_acc did not improve from 0.76481
Epoch 41/1000
 - 0s - loss: 0.4696 - acc: 0.7700 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00041: val_acc did not improve from 0.76481

Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 42/1000
 - 0s - loss: 0.4732 - acc: 0.7659 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00042: val_acc did not improve from 0.76481
Epoch 43/1000
 - 0s - loss: 0.4736 - acc: 0.7639 - val_loss: 0.4887 - val_acc: 0.7639

Epoch 00043: val_acc did not improve from 0.76481
Epoch 44/1000
 - 0s - loss: 0.4742 - acc: 0.7689 - val_loss: 0.4887 - val_acc: 0.7639
Using TensorFlow backend.

Epoch 00044: val_acc did not improve from 0.76481

Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 00044: early stopping
Test f1 score : 0.6920534672005954 
Test accuracy score : 0.7835795259361045 
