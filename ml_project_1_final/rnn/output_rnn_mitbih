Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 5173966: <python RNN_mitbih.py> in cluster <leonhard> Done

Job <python RNN_mitbih.py> was submitted from host <lo-login-02> by user <mchevalley> in cluster <leonhard> at Tue Mar 10 14:37:27 2020
Job was executed on host(s) <lo-s4-029>, in queue <gpu.24h>, as user <mchevalley> in cluster <leonhard> at Tue Mar 10 14:37:51 2020
</cluster/home/mchevalley> was used as the home directory.
</cluster/home/mchevalley/ml_project1> was used as the working directory.
Started at Tue Mar 10 14:37:51 2020
Terminated at Tue Mar 10 14:58:31 2020
Results reported at Tue Mar 10 14:58:31 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python RNN_mitbih.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2114.41 sec.
    Max Memory :                                 2952 MB
    Average Memory :                             2882.53 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               1144.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                21
    Run time :                                   1243 sec.
    Turnaround time :                            1264 sec.

The output (if any) follows:

2020-03-10 14:37:57.015975: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-10 14:37:57.016258: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/hdf5-1.10.1-z22q436tpg5j5mrbfk4xex6k2dg73tfo/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-03-10 14:37:57.016274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-03-10 14:38:05.187514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-10 14:38:05.252389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 computeCapability: 6.1
coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s
2020-03-10 14:38:05.256124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 14:38:05.281148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-10 14:38:05.298216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-10 14:38:05.306309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-10 14:38:05.334895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-10 14:38:05.343760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-10 14:38:05.395213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-10 14:38:05.402492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-10 14:38:05.403262: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-10 14:38:05.410808: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199875000 Hz
2020-03-10 14:38:05.410957: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5993bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-10 14:38:05.410978: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-10 14:38:05.599265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a021d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-10 14:38:05.599297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
2020-03-10 14:38:05.603800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 computeCapability: 6.1
coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s
2020-03-10 14:38:05.603856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 14:38:05.603877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-10 14:38:05.603894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-10 14:38:05.603911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-10 14:38:05.603928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-10 14:38:05.603944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-10 14:38:05.603961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-10 14:38:05.608417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-10 14:38:05.609755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-10 14:38:05.612903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-10 14:38:05.612919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-10 14:38:05.612928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-10 14:38:05.618725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7606 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:0e:00.0, compute capability: 6.1)
2020-03-10 14:38:09.516587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 187, 256)          66048     
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 124)               47244     
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 625       
=================================================================
Total params: 113,917
Trainable params: 113,917
Non-trainable params: 0
_________________________________________________________________
Train on 78798 samples, validate on 8756 samples
Epoch 1/1000
 - 30s - loss: 0.6786 - acc: 0.8239 - val_loss: 0.6644 - val_acc: 0.8235

Epoch 00001: val_acc improved from -inf to 0.82355, saving model to rnn_mitbih.h5
Epoch 2/1000
 - 29s - loss: 0.6037 - acc: 0.8277 - val_loss: 0.5414 - val_acc: 0.8241

Epoch 00002: val_acc improved from 0.82355 to 0.82412, saving model to rnn_mitbih.h5
Epoch 3/1000
 - 29s - loss: 0.5319 - acc: 0.8286 - val_loss: 0.5289 - val_acc: 0.8262

Epoch 00003: val_acc improved from 0.82412 to 0.82618, saving model to rnn_mitbih.h5
Epoch 4/1000
 - 29s - loss: 0.5137 - acc: 0.8320 - val_loss: 0.5148 - val_acc: 0.8297

Epoch 00004: val_acc improved from 0.82618 to 0.82972, saving model to rnn_mitbih.h5
Epoch 5/1000
 - 29s - loss: 0.4424 - acc: 0.8676 - val_loss: 0.4118 - val_acc: 0.8751

Epoch 00005: val_acc improved from 0.82972 to 0.87506, saving model to rnn_mitbih.h5
Epoch 6/1000
 - 29s - loss: 0.3518 - acc: 0.8949 - val_loss: 0.3228 - val_acc: 0.9061

Epoch 00006: val_acc improved from 0.87506 to 0.90612, saving model to rnn_mitbih.h5
Epoch 7/1000
 - 29s - loss: 0.3115 - acc: 0.9112 - val_loss: 0.2817 - val_acc: 0.9185

Epoch 00007: val_acc improved from 0.90612 to 0.91846, saving model to rnn_mitbih.h5
Epoch 8/1000
 - 29s - loss: 0.2803 - acc: 0.9214 - val_loss: 0.3225 - val_acc: 0.9036

Epoch 00008: val_acc did not improve from 0.91846
Epoch 9/1000
 - 29s - loss: 0.2617 - acc: 0.9268 - val_loss: 0.2526 - val_acc: 0.9290

Epoch 00009: val_acc improved from 0.91846 to 0.92896, saving model to rnn_mitbih.h5
Epoch 10/1000
 - 29s - loss: 0.2620 - acc: 0.9262 - val_loss: 0.2633 - val_acc: 0.9277

Epoch 00010: val_acc did not improve from 0.92896
Epoch 11/1000
 - 29s - loss: 0.2446 - acc: 0.9314 - val_loss: 0.2256 - val_acc: 0.9371

Epoch 00011: val_acc improved from 0.92896 to 0.93707, saving model to rnn_mitbih.h5
Epoch 12/1000
 - 28s - loss: 0.2277 - acc: 0.9370 - val_loss: 0.2256 - val_acc: 0.9360

Epoch 00012: val_acc did not improve from 0.93707
Epoch 13/1000
 - 29s - loss: 0.2192 - acc: 0.9384 - val_loss: 0.2384 - val_acc: 0.9334

Epoch 00013: val_acc did not improve from 0.93707
Epoch 14/1000
 - 28s - loss: 0.2194 - acc: 0.9384 - val_loss: 0.2162 - val_acc: 0.9380

Epoch 00014: val_acc improved from 0.93707 to 0.93799, saving model to rnn_mitbih.h5
Epoch 15/1000
 - 29s - loss: 0.2181 - acc: 0.9397 - val_loss: 0.2103 - val_acc: 0.9446

Epoch 00015: val_acc improved from 0.93799 to 0.94461, saving model to rnn_mitbih.h5
Epoch 16/1000
 - 29s - loss: 0.2106 - acc: 0.9419 - val_loss: 0.2190 - val_acc: 0.9414

Epoch 00016: val_acc did not improve from 0.94461
Epoch 17/1000
 - 28s - loss: 0.2011 - acc: 0.9454 - val_loss: 0.1998 - val_acc: 0.9454

Epoch 00017: val_acc improved from 0.94461 to 0.94541, saving model to rnn_mitbih.h5
Epoch 18/1000
 - 29s - loss: 0.1892 - acc: 0.9494 - val_loss: 0.1881 - val_acc: 0.9504

Epoch 00018: val_acc improved from 0.94541 to 0.95043, saving model to rnn_mitbih.h5
Epoch 19/1000
 - 29s - loss: 0.1941 - acc: 0.9474 - val_loss: 0.1910 - val_acc: 0.9487

Epoch 00019: val_acc did not improve from 0.95043
Epoch 20/1000
 - 29s - loss: 0.1883 - acc: 0.9491 - val_loss: 0.1793 - val_acc: 0.9520

Epoch 00020: val_acc improved from 0.95043 to 0.95203, saving model to rnn_mitbih.h5
Epoch 21/1000
 - 29s - loss: 0.1775 - acc: 0.9520 - val_loss: 0.1787 - val_acc: 0.9520

Epoch 00021: val_acc did not improve from 0.95203
Epoch 22/1000
 - 29s - loss: 0.1818 - acc: 0.9503 - val_loss: 0.2091 - val_acc: 0.9429

Epoch 00022: val_acc did not improve from 0.95203
Epoch 23/1000
 - 29s - loss: 0.1792 - acc: 0.9512 - val_loss: 0.1920 - val_acc: 0.9470

Epoch 00023: val_acc did not improve from 0.95203

Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 24/1000
 - 29s - loss: 0.1569 - acc: 0.9576 - val_loss: 0.1671 - val_acc: 0.9536

Epoch 00024: val_acc improved from 0.95203 to 0.95363, saving model to rnn_mitbih.h5
Epoch 25/1000
 - 29s - loss: 0.1541 - acc: 0.9587 - val_loss: 0.1648 - val_acc: 0.9555

Epoch 00025: val_acc improved from 0.95363 to 0.95546, saving model to rnn_mitbih.h5
Epoch 26/1000
 - 29s - loss: 0.1528 - acc: 0.9589 - val_loss: 0.1637 - val_acc: 0.9558

Epoch 00026: val_acc improved from 0.95546 to 0.95580, saving model to rnn_mitbih.h5
Epoch 27/1000
 - 28s - loss: 0.1522 - acc: 0.9593 - val_loss: 0.1631 - val_acc: 0.9558

Epoch 00027: val_acc did not improve from 0.95580
Epoch 28/1000
 - 29s - loss: 0.1522 - acc: 0.9592 - val_loss: 0.1624 - val_acc: 0.9560

Epoch 00028: val_acc improved from 0.95580 to 0.95603, saving model to rnn_mitbih.h5
Epoch 29/1000
 - 29s - loss: 0.1512 - acc: 0.9593 - val_loss: 0.1619 - val_acc: 0.9559

Epoch 00029: val_acc did not improve from 0.95603
Epoch 30/1000
 - 29s - loss: 0.1508 - acc: 0.9597 - val_loss: 0.1632 - val_acc: 0.9553

Epoch 00030: val_acc did not improve from 0.95603
Epoch 31/1000
 - 29s - loss: 0.1512 - acc: 0.9592 - val_loss: 0.1651 - val_acc: 0.9557

Epoch 00031: val_acc did not improve from 0.95603

Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 32/1000
 - 29s - loss: 0.1481 - acc: 0.9604 - val_loss: 0.1593 - val_acc: 0.9571

Epoch 00032: val_acc improved from 0.95603 to 0.95706, saving model to rnn_mitbih.h5
Epoch 33/1000
 - 29s - loss: 0.1475 - acc: 0.9604 - val_loss: 0.1594 - val_acc: 0.9567

Epoch 00033: val_acc did not improve from 0.95706
Epoch 34/1000
 - 28s - loss: 0.1473 - acc: 0.9607 - val_loss: 0.1592 - val_acc: 0.9569

Epoch 00034: val_acc did not improve from 0.95706
Epoch 35/1000
 - 29s - loss: 0.1473 - acc: 0.9605 - val_loss: 0.1593 - val_acc: 0.9565

Epoch 00035: val_acc did not improve from 0.95706

Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 36/1000
 - 28s - loss: 0.1470 - acc: 0.9607 - val_loss: 0.1590 - val_acc: 0.9569

Epoch 00036: val_acc did not improve from 0.95706
Epoch 37/1000
 - 28s - loss: 0.1469 - acc: 0.9606 - val_loss: 0.1590 - val_acc: 0.9568

Epoch 00037: val_acc did not improve from 0.95706
Epoch 38/1000
 - 28s - loss: 0.1469 - acc: 0.9606 - val_loss: 0.1590 - val_acc: 0.9567

Epoch 00038: val_acc did not improve from 0.95706

Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 39/1000
 - 28s - loss: 0.1468 - acc: 0.9605 - val_loss: 0.1590 - val_acc: 0.9567

Epoch 00039: val_acc did not improve from 0.95706
Epoch 40/1000
 - 29s - loss: 0.1468 - acc: 0.9605 - val_loss: 0.1590 - val_acc: 0.9567

Epoch 00040: val_acc did not improve from 0.95706
Epoch 41/1000
 - 29s - loss: 0.1468 - acc: 0.9605 - val_loss: 0.1590 - val_acc: 0.9567

Epoch 00041: val_acc did not improve from 0.95706

Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 42/1000
 - 29s - loss: 0.1468 - acc: 0.9605 - val_loss: 0.1590 - val_acc: 0.9567
Using TensorFlow backend.

Epoch 00042: val_acc did not improve from 0.95706
Epoch 00042: early stopping
Test f1 score : 0.7753418872727461 
Test accuracy score : 0.957701443449662 
